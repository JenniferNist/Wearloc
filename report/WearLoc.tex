\documentclass{sigchi-ext}
% Please be sure that you have the dependencies (i.e., additional
% LaTeX packages) to compile this example.
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage[scaled=.92]{helvet} % for proper fonts
\usepackage{graphicx} % for EPS use the graphics package instead
\usepackage{balance}  % for useful for balancing the last columns
\usepackage{booktabs} % for pretty table rules
\usepackage{ccicons}  % for Creative Commons citation icons
\usepackage{ragged2e} % for tighter hyphenation

% Some optional stuff you might like/need.
% \usepackage{marginnote} 
% \usepackage[shortlabels]{enumitem}
% \usepackage{paralist}
% \usepackage[utf8]{inputenc} % for a UTF8 editor only

% Paper metadata (use plain text, for PDF inclusion and later
% re-using, if desired).  Use \emtpyauthor when submitting for review
% so you remain anonymous.
\def\plaintitle{WearLoc: A Wearable Indoor Localization Device} \def\plainauthor{Rick Gelhausen, Jennifer Nist, Lukas Gemein, David Speck
  , Andre Biedenkapp}
\def\emptyauthor{}
\def\plainkeywords{Authors' choice; of terms; separated; by
  semicolons; include commas, within terms only; required.}
\def\plaingeneralterms{Documentation, Standardization}

\title{WearLoc: A Wearable Indoor Localization Device}

\numberofauthors{5}
% Notice how author names are alternately typesetted to appear ordered
% in 2-column format; i.e., the first 4 autors on the first column and
% the other 4 auhors on the second column. Actually, it's up to you to
% strictly adhere to this author notation.
\author{%
  \alignauthor{%
    \textbf{Lukas Gemein}\\
    \email{gemeinl@cs.uni-freiburg.de} }\alignauthor{%
    \textbf{Jennifer Nist}\\
    \email{nistj@cs.uni-freiburg.de} } \vfil \alignauthor{%
    \textbf{Rick Gelhausen}\\
    \email{rick.gelhausen@gmail.com} }\alignauthor{%
    \textbf{David Speck}\\
    \email{speckd@cs.uni-freiburg.de} } \vfil \alignauthor{%
    \textbf{Andre Biedenkapp}\\   
    \email{biedenka@cs.uni-freiburg.de}}} 

% Make sure hyperref comes last of your loaded packages, to give it a
% fighting chance of not being over-written, since its job is to
% redefine many LaTeX commands.
\definecolor{linkColor}{RGB}{6,125,233}
\hypersetup{%
  pdftitle={\plaintitle},
%  pdfauthor={\plainauthor},
  pdfauthor={\emptyauthor},
  pdfkeywords={\plainkeywords},
  bookmarksnumbered,
  pdfstartview={FitH},
  colorlinks,
  citecolor=black,
  filecolor=black,
  linkcolor=black,
  urlcolor=linkColor,
  breaklinks=true,
}

% \reversemarginpar%

\begin{document}

\maketitle

% Uncomment to disable hyphenation (not recommended)
% https://twitter.com/anjirokhan/status/546046683331973120
\RaggedRight{} 

\section{Introduction}
Firefighters and other rescue teams often have to examine buildings or tunnels to find and save survivors of tragic events. Therefore they need to enter unknown environment where it can be hard to not lose the orientation. Even if the rescue team has a map of the building, it can be difficult to share the position of a located survivor with other members of the team, since ways can be blocked or impassible due to destructions. It would be desirable to create maps of the surroundings that are up-to-date, which could make the work for rescue teams much easier and safer.\\
Another area of application for a wearable mapping device would be the exploration of caves to simplify and secure the work of cave explorers.\\
In the lab course "Wearable Computing Systems" we created two versions of a wearable device to create live-maps. The main difference of the versions lie in the hardware we used. Our first version uses a Raspberry Pi and the RPLIDAR laser scanner, which makes it a cheap and easy to rebuild system. In the second step we created a handier and even more powerful version using an Intel Edison and a Hokuyo laser scanner.

\newpage
\section{Hardware}
\subsection{Raspberry Pi}
The Raspberry Pi 2 Model B features a 900MHz quad-core CPU and 1GB of RAM. We use the Raspberry Pi in our first setup to run the entire software for IMU and laser scanner as well as a SLAM approach. Since the Raspberry Pi lacks a display we send the results via Wi-Fi to an external device to visualize the map.

\subsection{Intel Edison}
The Intel Edison features a 500MHz CPU and 1GB of RAM, which we use in our second version. It also runs the software for IMU and laser scanner but sends the data to an external device which runs the SLAM approach and visualizes the data.

\subsection{Laser Scanner Robo Peak (RPLIDAR)}
The RPLIDAR is a 360 degree 2D laser scanner. The scan range is 0.2 to 6m with a scan rate of 5.5Hz. Due to its relatively large rotating part and the associate motor, the RPLIDAR is quite big for a wearable device, having a surface of about 70x100 $mm^2$. We use it in our first setup mounted on a one-handed portable platform.

\subsection{Laser Scanner Hokuyo (URG-04LX)}
The Hokuyo URG-04LX laser scanner has a 240 degree measurement angle and offers a scan rate of 10Hz. The scan range is 0.02 to 4m. With its 40x40 $mm^2$ surface it is ideal to be mounted on a GoPro camera holder, which allows several different wearable designs.

\subsection{Grove IMU}
The Grove IMU 9DOF v2.0 features a gyroscope, a magnetometer and an accelerometer. We use the Grove IMU in both our setups to measure the bearing of the laser scanners to track user rotation. Thus, it helps to better predict the location.

\section{Software}
Both the Raspberry Pi and the Intel Edison run the Robot Operating System (ROS), which is an open source and free to use software. Our project is based on a ROS package which implements an approach for indoor SLAM. The package is called hector\_slam\footnote{ Kohlbrecher, S., Meyer, J., von Stryk, O., Klingauf, U.: A Flexible and Scalable
SLAM System with Full 3D Motion Estimation. In: IEEE International Symposium
on Safety, Security and Rescue Robotics (SSRR). IEEE, Kyoto (2011)} and was implemented by Team Hector of the University of Darmstadt. We also use the already existing packages i2c\_imu, rplidar\_ros and urg\_node and adapted them to our needs to conveniently use the IMU as well as the laser scanners. Additionally, we uploaded a binary blob onto the IMU to directly convert the raw measurements to quaternions which were then forwarded to the SLAM implementation. A Wi-Fi network connection was set up to wirelessly transfer data between the wearable and the external device used for visualization (Figure~\ref{fig:software}).

\begin{figure*}
  \includegraphics[width=\textwidth]{101.png}
  \caption{Live visualization of a SLAM run in rviz.}~\label{fig:software}
\end{figure*}

\section{Wearbale v1}
In our first version we used the Raspberry PI, the IMU and the RPLIDAR laser scanner. We chose to start with the Raspberry Pi, since it offers an easy start due to its numerous ports to connect other devices. The IMU was connected using the I2C GPIO pins of the Raspberry Pi whereas the laser scanner could easily be connected through a USB port. This fast setup allowed us to get familiar with the use of the IMU and the RPLIDAR, have a look at raw data and already start adapting the code. Finally, the Raspberry Pi runs all Software components itself, including the packages for IMU and RPLIDAR as well as the SLAM approach. The map is wirelessly transferred to a laptop which is used for visualization. All the hardware components are mounted onto a wooden plate which is screwed on a aluminium table leg for the purpose of holding the device (Figure~\ref{fig:v1}). A powerbank with 2.1A powers the system. Since the Raspberry Pi and the laser scanner are relatively big this version is not quite as handy which is why we created a second version. Note, that apart from small adjustments the Raspberry Pi and the Intel Edison are interchangeable.

\begin{figure}
  \includegraphics[width=0.9\columnwidth]{pi-lidar.jpg}
  \caption{Wearable v1 featuring the Raspberry Pi and the RPLIDAR.}~\label{fig:v1}
\end{figure}

\section{Wearable v2}
The Intel Edison does not offer GPIO pins or USB ports to directly connect our sensors which is why we designed a circuit board that holds the Intel Edison and offers the appropriate ports. The making of the board took some time, which is why we already started developing the software using the Raspberry Pi (Wearable v1). Since the Hokuyo laser scanner is very small, it is better suited for a wearable device. In contrast to the Raspberry Pi, the Intel Edison runs a lightweigth version of ROS which was built from source. Due to memory limitations we only set up the packages i2c\_imu and urg\_node necessary for the sensors.
The SLAM approach as well as the visualization run on a laptop that receives the sensor data wirelessly. The Hokuyo laser scanner is small enough to be mounted on a 3D printed platform that can be attached to GoPro camera holders. The IMU is attached to the bottom of the platform. As there is an enormous amount of different GoPro camera holders, this allows us to attach the laser scanner and the IMU in many different ways e.g. as a head mounted gear similar to a helmet lamp which leaves both hands free for other tasks. This system is powered by a 1A powerbank. We also created a 3D printed box, s.t. the Intel Edison can safely be transported and used in the pockets of the wearer. 

\begin{figure}[!h]
  \includegraphics[width=0.9\columnwidth]{edison-hokuyo.jpg}
  \caption{Wearable v2 featuring the Intel Edison and the Hokuyo.}~\label{fig:v2}
\end{figure}

\section{Results}
The presented wearable devices yield good mapping results. Because of its higher scan range of 5.5m, the RPLIDAR outperforms the Hokuyo with regard to the SLAM results. It returns more reference points which helps to better estimate the location. Both the RPLIDAR and the Hokuyo laser scanner have a low scan rate leading to bad results during fast movements. In our opinion, the results can be improved significantly with a 

\begin{figure}[!h]
	\hspace{1cm}
	\includegraphics[width=0.85\textwidth]{51.png}
	\caption{A groundplan of building 51 (Technical Faculty, University of Freiburg) combined with a map generated by the wearable device (v1).}~\label{fig:b51map}
\end{figure}

more powerful scanner that overcomes the drawbacks of low scan rate and range. Nevertheless, sticking to the laser scanner limits the presented wearable devices can be used for simultaneous localization and mapping as seen in Figure~\ref{fig:b51map}. It shows a map that was generated with the first version of our wearable device and afterwards matched to the groundplan of the building. The map fits the groundplan very well and realistically reflects the building. Thus, both provided wearable SLAM devices can be used to construct meaningful representations of the environment.



%\bibliographystyle{SIGCHI-Reference-Format}
%\bibliography{sample}

\balance{} 
\end{document}